---
title: "fastballs"
output: html_document
date: "2024-06-14"
---

# Introduction

This is the cleaned version of my regression analysis for my STA302 final project, as my old Markdown file had too much busy work. I will document my data and create graphs here for the sake of organization while writing my final report.

We will work with two datasets: savant_data.csv, which contains the bulk of our working data courtesy of Major League Baseball's Statcast, and pitchbot.csv, which contains command data courtesy of Cameron Groove's Pitching Bot on Fangraphs.

# Data Processing
Let's begin by loading in the necessary libraries and cleaning our data.

```{r, message = FALSE, warning = FALSE}
# Libraries
library(car)
library(tidyverse)

# Loading and cleaning data
fb <- read_csv("savant_data.csv")
fb <- fb %>% select(player_id, total, `downward movement w/ gravity (in)`, 
                    `glove/arm-side movement (in)`, whiff_percent, `pitch (MPH)`,
                    `spin (RPM)`, `vertical release pt (ft)`, `extension (ft)`)

bot <- read_csv("botcmd.csv") %>% select(player_id, `botCmd FA`)

# Merging and cleaning data
fastballs <- merge(fb, bot, by = 'player_id')
renamed_cols <- c('downwards_mvmt' = 'downward movement w/ gravity (in)',
                  'side_mvmt' = 'glove/arm-side movement (in)',
                  'speed' = 'pitch (MPH)',
                  'spin' = 'spin (RPM)',
                  'release_pt' = 'vertical release pt (ft)',
                  'extension' = 'extension (ft)',
                  'command' = 'botCmd FA')

fastballs <- rename(fastballs, renamed_cols)
```

Now we will preview our data
```{r}
head(fastballs)
```

# Regression
Now we will begin training different models. We will split our model 75-25 into training-validation data.

```{r, message = FALSE}
set.seed(1000)
fastballs_training <- fastballs %>% sample_frac(size = 0.8)
fastballs_validation <- anti_join(fastballs, fastballs_training)
fastballs_training
```

## EDA
(eda)

```{r}
summarize(fastballs_training, pitchers = n(), 
          `min speed` = min(speed), `max speed` = max(speed),
          `average speed` = mean(speed), `median speed` = median(speed), 
          `sd speed` = sd(speed))
```

## Model Selection
We will proceed by backwards elimination, so we will create our first model using every possible parameter.

### Model 1
```{r}
reg_all <- lm(whiff_percent ~ speed + spin + downwards_mvmt + 
              side_mvmt + release_pt + extension + command, 
              data = fastballs_training)

summary(reg_all)
```

Let's check the assumptions of normality, linearity, and constant variance:
```{r pressure, echo=FALSE}
par(mfrow = c(1,2))
plot(reg_all)


plot(reg_all$residuals ~ fastballs_training$speed,
     main = 'Speed',
     xlab = 'Speed (MPH)', ylab = 'Residuals',
     col = 'lightcoral')
plot(reg_all$residuals ~ fastballs_training$spin,
     main = 'Spin',
     xlab = 'Spin (RPM)', ylab = 'Residuals',
     col = 'orange')
plot(reg_all$residuals ~ fastballs_training$downwards_mvmt,
     main = 'Downwards Movement',
     xlab = 'Downwards Movement (in)', ylab = 'Residuals',
     col = 'goldenrod')
plot(reg_all$residuals ~ fastballs_training$side_mvmt,
     main = 'Side Movement',
     xlab = 'Side Movement (in)', ylab = 'Residuals',
     col = 'darkseagreen')
plot(reg_all$residuals ~ fastballs_training$release_pt,
     main = 'Release Point',
     xlab = 'Release Point (ft)', ylab = 'Residuals',
     col = 'cadetblue')
plot(reg_all$residuals ~ fastballs_training$extension,
     main = 'Extension',
     xlab = 'Extension (ft)', ylab = 'Residuals',
     col = 'plum')
plot(reg_all$residuals ~ fastballs_training$command,
     main = 'Command',
     xlab = 'Command (Bot Command Rating)', ylab = 'Residuals',
     col = 'gray')
```
Now let's also check multicollinearity by looking at the Variance Inflation Factor:
```{r}
vif(reg_all)
```

Based on the above, it seems like there may be some outliers. It also appears like every assumption is satisfied, except potentially linearity and multicollinearity. The former we might address through a transformation. The latter, while indeed indicating some degree of multicollinearity (the first five predictors in particular, since they seem to be a notable degree larger than 1), is not necessary to address since the VIF $< 5$. 

There are two possibilities for transformations:
1. We use Box-Cox to decide on a power transformation.
2. We use the arcsine variance stabilizing transformation, since our predicted value is a percentage. 

Let's see how both perform. First, to decide on a power transformation:
```{r}
MASS::boxcox(reg_all)
```
Based on the Box-Cox plot, because $1$ is closeset to the Maximum Likelihood Estimator, no transformation seems necessary. Let's proceed with the arcsine transformation and see if it's any help.

```{r}
# Arcsine transformed response
asine_whiff_percent <- asin(sqrt(fastballs_training$whiff_percent / 100))

# Transformed regression
asine_reg_all <- lm(asine_whiff_percent ~ speed + spin + downwards_mvmt + 
                    side_mvmt + release_pt + extension + command, 
                    data = fastballs_training)
summary(asine_reg_all)

par(mfrow = c(1,2))
plot(asine_reg_all)
plot(reg_all)
```

It actually looks a little worse. Either way, it looks like point 27, associated with Shane Bieber, is the worst performer. Let's look at his standardized residual:

```{r}
rstandard(reg_all)[27]
rstandard(asine_reg_all)[27]
```
At this range, whether or not we remove him seems to be a bit of a judgement call. Let's try removing him and see what happens.

```{r}
updated_fastballs_training <- fastballs_training %>%  filter(player_id != 669456) 
updated_fastballs_training
```

```{r}
reg_all_removed <- lm(whiff_percent ~ speed + spin + downwards_mvmt + 
                      side_mvmt + release_pt + extension + command, 
                      data = updated_fastballs_training)

summary(reg_all_removed)
par(mfrow = c(1,2))
plot(reg_all_removed)
```

```{r}
# Arcsine version
arcsine_reg_all_removed <- lm(asin(sqrt(updated_fastballs_training$whiff_percent / 100)) ~
                              speed + spin + downwards_mvmt + side_mvmt + release_pt + 
                              extension + command, data = updated_fastballs_training)
summary(arcsine_reg_all_removed)

par(mfrow = c(2,2))
plot(arcsine_reg_all_removed)
```
Normality seems to look better in both cases, although it still seems like the non-transformed data looks best. Speed is no longer significant, and downwards movement and side movement have become more significant. Let's proceed with with the non-transformed data set with Bieber removed.

### Model 2.1, 2.2

The least significant of the previous ones was side movement. Let's try removing that.
```{r}
reg_sdr <- lm(whiff_percent ~ spin + downwards_mvmt + release_pt, 
              data = updated_fastballs_training)

summary(reg_sdr)
```

Was this okay? Let's validate with the partial $F$ test.

```{r}
anova(reg_all_removed, reg_sdr)
```
It looks like even this was significant, so no, we cannot proceed.

Let's try removing everything then.

```{r}
reg_sdsr <- lm(whiff_percent ~ spin + downwards_mvmt + side_mvmt + 
                 release_pt, data = updated_fastballs_training)

summary(reg_sdsr)
```

Let's confirm if we can remove speed, extension, and command using a partial $F$ test.
```{r}
anova(reg_all_removed, reg_sdsr)
```

Since $p = 0.4534$, it looks like we are good to go. Let's recheck our assumptions:
```{r pressure, echo=FALSE}
par(mfrow = c(1,2))
plot(reg_sdsr)

plot(reg_sdsr$residuals ~ updated_fastballs_training$spin,
     main = 'Spin',
     xlab = 'Spin (RPM)', ylab = 'Residuals',
     col = 'orange')
plot(reg_sdsr$residuals ~ updated_fastballs_training$downwards_mvmt,
     main = 'Downwards Movement',
     xlab = 'Downwards Movement (in)', ylab = 'Residuals',
     col = 'goldenrod')
plot(reg_sdsr$residuals ~ updated_fastballs_training$side_mvmt,
     main = 'Side Movement',
     xlab = 'Side Movement (in)', ylab = 'Residuals',
     col = 'darkseagreen')
plot(reg_sdsr$residuals ~ updated_fastballs_training$release_pt,
     main = 'Release Point',
     xlab = 'Release Point (ft)', ylab = 'Residuals',
     col = 'cadetblue')
```

Normality still looks good, although there seems to be some fanning behavior in the residuals. Let's re-introduce the arcsine transformation and see if it's any help this time around.

```{r}
# Arcsine version
arcsine_reg_sdsr_removed <- lm(asin(sqrt(updated_fastballs_training$whiff_percent / 100)) ~
                              spin + downwards_mvmt + side_mvmt + release_pt, 
                              data = updated_fastballs_training)

summary(arcsine_reg_sdsr_removed)

par(mfrow = c(1,2))
plot(arcsine_reg_sdsr_removed)
plot(arcsine_reg_sdsr_removed$residuals ~ updated_fastballs_training$spin,
     main = 'Spin',
     xlab = 'Spin (RPM)', ylab = 'Residuals',
     col = 'orange')
plot(arcsine_reg_sdsr_removed$residuals ~ updated_fastballs_training$downwards_mvmt,
     main = 'Downwards Movement',
     xlab = 'Downwards Movement (in)', ylab = 'Residuals',
     col = 'goldenrod')
plot(arcsine_reg_sdsr_removed$residuals ~ updated_fastballs_training$side_mvmt,
     main = 'Side Movement',
     xlab = 'Side Movement (in)', ylab = 'Residuals',
     col = 'darkseagreen')
plot(arcsine_reg_sdsr_removed$residuals ~ updated_fastballs_training$release_pt,
     main = 'Release Point',
     xlab = 'Release Point (ft)', ylab = 'Residuals',
     col = 'cadetblue')
```

If anything, it looks worse. How about WLS?

```{r}
weights <- 1 / lm(abs(reg_sdsr$residuals) ~ reg_sdsr$fitted.values)$fitted.values^2

wls_reg_sdsr <- lm(whiff_percent ~ spin + downwards_mvmt + side_mvmt + release_pt,
                data = updated_fastballs_training, weights = weights)

summary(wls_reg_sdsr)
```

```{r pressure, echo=FALSE}
# WLS version
par(mfrow = c(1,2))
plot(wls_reg_sdsr)

plot(wls_reg_sdsr$residuals ~ updated_fastballs_training$spin,
     main = 'Spin',
     xlab = 'Spin (RPM)', ylab = 'Residuals',
     col = 'orange')
plot(wls_reg_sdsr$residuals ~ updated_fastballs_training$downwards_mvmt,
     main = 'Downwards Movement',
     xlab = 'Downwards Movement (in)', ylab = 'Residuals',
     col = 'goldenrod')
plot(wls_reg_sdsr$residuals ~ updated_fastballs_training$side_mvmt,
     main = 'Side Movement',
     xlab = 'Side Movement (in)', ylab = 'Residuals',
     col = 'darkseagreen')
plot(wls_reg_sdsr$residuals ~ updated_fastballs_training$release_pt,
     main = 'Release Point',
     xlab = 'Release Point (ft)', ylab = 'Residuals',
     col = 'cadetblue')
```

It looks like this model does the best at not validating assumptions. Let's check the last one: Multicollinearity

```{r}
vif(wls_reg_sdsr)
```

Which appears to still be fine.


### Models 3 & 4 (?)
Can we go simpler? Let's pick the two most significant parameters.
```{r}
reg_dr <- lm(whiff_percent ~ downwards_mvmt + release_pt,
                data = updated_fastballs_training)
summary(reg_dr)
```
Now let's conduct a partial F test to see if this was okay.

```{r}
anova(wls_reg_sdsr, reg_dr)
```
Which is very significant, so it appears like at least one of spin and side movement was significant. Let's take them up individually.

```{r}
reg_sdr <- lm(whiff_percent ~ spin + downwards_mvmt + release_pt,
                data = updated_fastballs_training)
summary(reg_sdr)
```

```{r}
anova(wls_reg_sdsr, reg_sdr)
```
So side movement was important. What about if we remove spin?

```{r}
reg_dsr <- lm(whiff_percent ~ downwards_mvmt + side_mvmt + release_pt,
                data = updated_fastballs_training)
summary(reg_dsr)
```

```{r}
anova(wls_reg_sdsr, reg_sdr)
```

Which is also significant. So it seems like we cannot go simpler.

# Selecting a model

Let's now compare our original model to our simplified model. We will use corrected AIC (since $n = 119$, $p \geq 4$, so $\frac{n}{K} = \frac{119}{4 + 2} \leq 40$), BIC, and adjusted $R^2$ to decide.
```{r}
models = c('All', 'Speed + Downwards Movement + Sideways Movement + Release Point')

n_predictors = c(7, 4)

adj_r_squared = c(summary(reg_all_removed)$adj.r.squared,
              summary(wls_reg_sdsr)$adj.r.squared)

bic = c(BIC(reg_all_removed), 
        BIC(wls_reg_sdsr))

aic_corrected = c(AIC(reg_all_removed) + (2*9*10)/(119-9+1), 
                AIC(wls_reg_sdsr) + (2*6*7)/(103-6+1))

selection <- tibble(models, n_predictors, adj_r_squared, aic_corrected, bic)
selection
```

So by all counts, our second model is better. We'll pick that one to move onto our final step: Validation.

# Model Validation
```{r}
reg_sdsr_validation <- lm(whiff_percent ~ spin + downwards_mvmt + side_mvmt + release_pt,
                          data = fastballs_validation)

# summary(reg_sdsr_validation)

weights_val <- 1 / lm(abs(reg_sdsr_validation$residuals) ~ reg_sdsr_validation$fitted.values)$fitted.values^2

wls_reg_sdsr_val <- lm(whiff_percent ~ spin + downwards_mvmt + side_mvmt + release_pt,
                data = fastballs_validation, weights = weights_val)

summary(wls_reg_sdsr_val)
plot(wls_reg_sdsr_val)
# plot(reg_sdsr_validation)
```
It looks like point 15 has high leverage in this dataset (Felix Bautista), and point 12 and 2 are very close as well (. There also appear to be quite a few meaningful deviations away from the normal distribution. In particular, point 17 (Alex Faedo) and 15 (Felix Bautista) seem to be pretty far.

Let's compare with our test regression:
```{r}
models = c('Training', 'Validation')

n = c(119, 30)

adj_r_squared = c(summary(wls_reg_sdsr)$adj.r.squared,
                  summary(reg_sdsr_validation)$adj.r.squared)

intercept_estimate <- c(wls_reg_sdsr$coefficients[1],
                        reg_sdsr_validation$coefficients[1])

spin_estimate <- c(wls_reg_sdsr$coefficients[2],
                        reg_sdsr_validation$coefficients[2])

downwards_mvmt_estimate <- c(wls_reg_sdsr$coefficients[3],
                        reg_sdsr_validation$coefficients[3])

side_mvmt_estimate <- c(wls_reg_sdsr$coefficients[4],
                        reg_sdsr_validation$coefficients[4])

release_pt_estimate <- c(wls_reg_sdsr$coefficients[5],
                        reg_sdsr_validation$coefficients[5])

validation <- tibble(models, n, adj_r_squared, spin_estimate, downwards_mvmt_estimate,
                    side_mvmt_estimate, release_pt_estimate)
validation
```

So besides the spin estimate, they really aren't too similar. Let's also check that there's no multicollinearity, since that's never been an issue.

```{r}
vif(wls_reg_sdsr_val)
```

Let's take a look at the training dataset:

```{r}
summarize(fastballs_validation, pitchers = n(), 
          `min speed` = min(speed), `max speed` = max(speed),
          `average speed` = mean(speed), `median speed` = median(speed), 
          `sd speed` = sd(speed))
```

```{r}
summarize(updated_fastballs_training, pitchers = n(), 
          `min speed` = min(speed), `max speed` = max(speed),
          `average speed` = mean(speed), `median speed` = median(speed), 
          `sd speed` = sd(speed))
```

Let's also look at the number of total fastballs thrown by each group.
```{r}
mean(updated_fastballs_training$total)
mean(fastballs_validation$total)
```

Looks like the second group, on average, threw 100 less fastballs than the first. This might explain some of the deviations.


